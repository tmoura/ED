{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNorAsdVG3QObih5v8zXJQd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/ED/blob/master/Atividade4-Ciclo2-RESPOSTAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyZJR6oA5Of4"
      },
      "outputs": [],
      "source": [
        "!pip install deslib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from deslib.dcs import OLA\n",
        "from deslib.dcs import LCA\n",
        "from deslib.dcs import MCB\n",
        "from deslib.des import KNORAE\n",
        "from deslib.des import KNORAU\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/datasets/ionosphere.data\"\n",
        "\n",
        "# Carregar base de dados\n",
        "# DataFrame\n",
        "dataset = pd.read_csv(url, header=None)\n",
        "\n",
        "columns = len(dataset.columns)\n",
        "\n",
        "y = dataset[0] # extrai a primeira coluna, que é o label\n",
        "X = dataset.loc[:,1:columns-1]\n",
        "\n",
        "# Transforma para Array NumPy\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "HMndtF92hIK6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "folds = 10\n",
        "\n",
        "kf = StratifiedKFold(n_splits = folds)\n",
        "\n",
        "## 10 conjuntos de dados\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for train_index, test_index in kf.split(X,y):\n",
        "  X_train.append(X[train_index])\n",
        "  X_test.append(X[test_index])\n",
        "\n",
        "  y_train.append(y[train_index])\n",
        "  y_test.append(y[test_index])"
      ],
      "metadata": {
        "id": "tMTEOim8PJLA"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultsDC = []\n",
        "resultsRF = []\n",
        "\n",
        "for i in range(folds):\n",
        "  dc = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "  dc.fit(X_train[i], y_train[i])\n",
        "\n",
        "  rf = RandomForestClassifier()\n",
        "  rf.fit(X_train[i], y_train[i])\n",
        "\n",
        "  resultsDC.append(dc.score(X_test[i], y_test[i]))\n",
        "  resultsRF.append(rf.score(X_test[i], y_test[i]))\n",
        "\n",
        "\n",
        "print('Árvore de Decisão: ', np.mean(resultsDC))\n",
        "print('Random Forest: ', np.mean(resultsRF))"
      ],
      "metadata": {
        "id": "p_cWYRvOiJop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e289fd-a34d-40ff-c704-44f68482637d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Árvore de Decisão:  0.8746825396825397\n",
            "Random Forest:  0.9088095238095237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "\n",
        "resultsBAG = []\n",
        "resultsKNE = []\n",
        "resultsKNU = []\n",
        "resultsLCA = []\n",
        "resultsOLA = []\n",
        "resultsMCB = []\n",
        "\n",
        "for i in range(folds):\n",
        "  bag = BaggingClassifier(n_estimators=50)\n",
        "  bag.fit(X_train[i], y_train[i])\n",
        "\n",
        "  resultsBAG.append(bag.score(X_test[i], y_test[i]))\n",
        "\n",
        "  X_new, X_dsel, y_new, y_dsel = train_test_split(X_train[i], y_train[i], test_size=0.5,random_state=None)\n",
        "\n",
        "  kne = KNORAE(bag, k=5)\n",
        "  mcb = MCB(bag, k=5)\n",
        "  lca = LCA(bag, k=5)\n",
        "  ola = OLA(bag, k=5)\n",
        "  knu = KNORAU(bag, k=5)\n",
        "\n",
        "  # Fitting the des techniques\n",
        "  kne.fit(X_dsel, y_dsel)\n",
        "  mcb.fit(X_dsel, y_dsel)\n",
        "  lca.fit(X_dsel, y_dsel)\n",
        "  ola.fit(X_dsel, y_dsel)\n",
        "  knu.fit(X_dsel, y_dsel)\n",
        "\n",
        "  resultsKNE.append(kne.score(X_test[i], y_test[i]))\n",
        "  resultsKNU.append(knu.score(X_test[i], y_test[i]))\n",
        "  resultsLCA.append(lca.score(X_test[i], y_test[i]))\n",
        "  resultsOLA.append(ola.score(X_test[i], y_test[i]))\n",
        "  resultsMCB.append(mcb.score(X_test[i], y_test[i]))\n",
        "\n",
        "# Calculate classification accuracy of each technique\n",
        "print('KNORA-Eliminate: ',np.mean(resultsKNE))\n",
        "print('KNORA-Union: ',np.mean(resultsKNU))\n",
        "print('MCB: ',np.mean(resultsMCB))\n",
        "print('OLA: ',np.mean(resultsOLA))\n",
        "print('LCA: ',np.mean(resultsLCA))\n",
        "print('Bagging: ',np.mean(resultsBAG))"
      ],
      "metadata": {
        "id": "hJiBkaitzF0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
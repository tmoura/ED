{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbQDH9P9TJilGHoXGoUTNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmoura/ED/blob/master/13_exerc%C3%ADcios_regressao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3zNAo4jbCKF"
      },
      "outputs": [],
      "source": [
        "## Exercício 1 - Dataset car_crashes do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"car_crashes\"do seaborn\n",
        "# 2) Dropar a coluna \"abbrev\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'total' para o target (coluna objetivo - y) e o restante para o X\n",
        "# 4) Normalizar todo o X\n",
        "\n",
        "# df = X.values\n",
        "# min_max_scaler = preprocessing.MinMaxScaler()\n",
        "# x_scaled = min_max_scaler.fit_transform(df)\n",
        "# X = pd.DataFrame(x_scaled)\n",
        "\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo linear\n",
        "# 7) Treinar uma árvores de regressão\n",
        "# 8) Treinar um KNN para regressão\n",
        "# 9) Apresentar os resultados dos erros usando: MSE, MAE e RMSE para os 3 modelos\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = sns.load_dataset(\"car_crashes\")\n",
        "\n",
        "data = data.drop(['abbrev'],axis=1)\n",
        "\n",
        "y = data['total'].copy()\n",
        "X = data.iloc[:,1:6].copy()\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "X['speeding'] = MinMaxScaler().fit_transform(np.array(X['speeding']).reshape(-1,1))\n",
        "X['alcohol'] = MinMaxScaler().fit_transform(np.array(X['alcohol']).reshape(-1,1))\n",
        "X['not_distracted'] = MinMaxScaler().fit_transform(np.array(X['not_distracted']).reshape(-1,1))\n",
        "X['no_previous'] = MinMaxScaler().fit_transform(np.array(X['no_previous']).reshape(-1,1))\n",
        "X['ins_premium'] = MinMaxScaler().fit_transform(np.array(X['ins_premium']).reshape(-1,1))\n",
        "\n",
        "res = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=None)\n",
        "train_data, test_data, train_labels, test_labels = res\n",
        "\n",
        "###############\n",
        "regr1 = linear_model.LinearRegression()\n",
        "regr1.fit(train_data, train_labels)\n",
        "\n",
        "predictions1 = regr1.predict(test_data)\n",
        "print(mean_squared_error(test_labels, predictions1))\n",
        "\n",
        "###############\n",
        "regr2 = DecisionTreeRegressor()\n",
        "regr2.fit(train_data, train_labels)\n",
        "\n",
        "predictions2 = regr2.predict(test_data)\n",
        "print(mean_squared_error(test_labels, predictions2))\n",
        "\n",
        "###############\n",
        "regr3 = KNeighborsRegressor()\n",
        "regr3.fit(train_data, train_labels)\n",
        "\n",
        "predictions3 = regr3.predict(test_data)\n",
        "print(mean_squared_error(test_labels, predictions3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 2 - Dataset Parkinsons (dataset com 2 classes)\n",
        "\n",
        "# 1) Carregar o dataset \"parkinsons\" pela URL abaixo:\n",
        "\n",
        "# url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "# 2) Separar os dados y e X. A coluna y é a coluna 0 (zero)\n",
        "# 3) Normalizar todas as colunas de X (usando o mesmo código da questão anterior)\n",
        "# 4) Separar oa dados em treinamento e teste\n",
        "# 5) Treinar um modelo de regressão logística\n",
        "# 6) Treinar uma árvore de decisão\n",
        "# 7) Treinar um KNN para classificação\n",
        "# 8) Apresentar os resultados de acurácia em percentual\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/tmoura/machinelearning/master/parkinsons.data\"\n",
        "\n",
        "# Carregar base de dados\n",
        "dataset = pd.read_csv(url, header=None)\n",
        "\n",
        "columns = len(dataset.columns)\n",
        "\n",
        "y = dataset[0] # extrai a primeira coluna, que é o label\n",
        "X = dataset.loc[:,1:columns-1]\n",
        "\n",
        "x2 = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x2)\n",
        "df = pd.DataFrame(x_scaled)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=None, stratify=y) # 80% treino e 20% teste\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "result = model.predict(X_test)\n",
        "acc = metrics.accuracy_score(result, y_test)\n",
        "show = round(acc * 100)\n",
        "print(\"{}%\".format(show))\n",
        "\n",
        "###################\n",
        "\n",
        "model2 = DecisionTreeClassifier()\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "result2 = model2.predict(X_test)\n",
        "acc2 = metrics.accuracy_score(result2, y_test)\n",
        "show2 = round(acc2 * 100)\n",
        "print(\"{}%\".format(show2))\n",
        "\n",
        "###################\n",
        "\n",
        "model3 = KNeighborsClassifier()\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "result3 = model3.predict(X_test)\n",
        "acc3 = metrics.accuracy_score(result3, y_test)\n",
        "show3 = round(acc3 * 100)\n",
        "print(\"{}%\".format(show3))"
      ],
      "metadata": {
        "id": "NecXgZ5iytCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Exercício 3 - Dataset attention do seaborn\n",
        "\n",
        "# 1) Carregar o dataset \"attention\" do seaborn\n",
        "# 2) Fazer um LabelEncoder na coluna \"attention\"\n",
        "# 3) Separar o dataframe, deixando a coluna 'attention' para o target (coluna objetivo - y) e as colunas \"solutions\" e \"score\" para o X\n",
        "# 4) Normalizar todo o X usando o mesmo código da questão 1\n",
        "# 5) Separar os dados em treinamento e teste\n",
        "# 6) Treinar um modelo de regressão logística\n",
        "# 7) Treinar uma árvore de decisão\n",
        "# 8) Treinar um KNN para classificação\n",
        "# 9) Apresentar os resultados de acurárica em percentual\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "data = sns.load_dataset(\"attention\")\n",
        "\n",
        "### LabelEncoder coluna attention\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['attention']= label_encoder.fit_transform(data['attention'])\n",
        "\n",
        "y = data[\"attention\"]\n",
        "X = data[[\"solutions\",\"score\"]]\n",
        "\n",
        "x2 = X.values\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x2)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "##############\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y) # 80% treino e 20% teste\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "result = model.predict(X_test)\n",
        "acc = metrics.accuracy_score(result, y_test)\n",
        "show = round(acc * 100)\n",
        "print(\"{}%\".format(show))\n",
        "\n",
        "###################\n",
        "\n",
        "model2 = DecisionTreeClassifier()\n",
        "model2.fit(X_train, y_train)\n",
        "\n",
        "result2 = model2.predict(X_test)\n",
        "acc2 = metrics.accuracy_score(result2, y_test)\n",
        "show2 = round(acc2 * 100)\n",
        "print(\"{}%\".format(show2))\n",
        "\n",
        "###################\n",
        "\n",
        "model3 = KNeighborsClassifier()\n",
        "model3.fit(X_train, y_train)\n",
        "\n",
        "result3 = model3.predict(X_test)\n",
        "acc3 = metrics.accuracy_score(result3, y_test)\n",
        "show3 = round(acc3 * 100)\n",
        "print(\"{}%\".format(show3))"
      ],
      "metadata": {
        "id": "1PAlFH5Au-11"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}